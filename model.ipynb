{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (32, 224, 224, 3)\n",
      "Labels shape: (32,)\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 16s 823ms/step - loss: 4.4028 - accuracy: 0.0736\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 15s 812ms/step - loss: 2.0421 - accuracy: 0.2504\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 15s 807ms/step - loss: 2.0407 - accuracy: 0.2785\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 14s 797ms/step - loss: 1.6050 - accuracy: 0.4431\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 14s 782ms/step - loss: 1.3554 - accuracy: 0.5394\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 14s 770ms/step - loss: 1.2141 - accuracy: 0.5972\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 14s 775ms/step - loss: 1.0764 - accuracy: 0.6550\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 14s 798ms/step - loss: 0.9681 - accuracy: 0.6988\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 14s 792ms/step - loss: 0.8778 - accuracy: 0.7408\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 15s 835ms/step - loss: 0.8003 - accuracy: 0.7706\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 16s 896ms/step - loss: 0.7342 - accuracy: 0.8021\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 16s 866ms/step - loss: 0.6768 - accuracy: 0.8161\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 15s 841ms/step - loss: 0.6267 - accuracy: 0.8301\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 15s 837ms/step - loss: 0.5826 - accuracy: 0.8441\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 16s 861ms/step - loss: 0.5434 - accuracy: 0.8529\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 15s 844ms/step - loss: 0.5083 - accuracy: 0.8634\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 14s 791ms/step - loss: 0.4767 - accuracy: 0.8774\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 14s 783ms/step - loss: 0.4482 - accuracy: 0.8984\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 14s 769ms/step - loss: 0.4222 - accuracy: 0.9107\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 14s 767ms/step - loss: 0.3984 - accuracy: 0.9159\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 14s 769ms/step - loss: 0.3766 - accuracy: 0.9264\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 14s 770ms/step - loss: 0.3566 - accuracy: 0.9282\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 14s 769ms/step - loss: 0.3380 - accuracy: 0.9405\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 14s 770ms/step - loss: 0.3209 - accuracy: 0.9475\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 14s 787ms/step - loss: 0.3049 - accuracy: 0.9545\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 14s 774ms/step - loss: 0.2901 - accuracy: 0.9562\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 14s 778ms/step - loss: 0.2764 - accuracy: 0.9632\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 14s 780ms/step - loss: 0.2635 - accuracy: 0.9632\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 14s 772ms/step - loss: 0.2515 - accuracy: 0.9755\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 14s 799ms/step - loss: 0.2403 - accuracy: 0.9807\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 14s 788ms/step - loss: 0.2298 - accuracy: 0.9825\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 14s 787ms/step - loss: 0.2200 - accuracy: 0.9825\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 14s 771ms/step - loss: 0.2107 - accuracy: 0.9825\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 14s 769ms/step - loss: 0.2021 - accuracy: 0.9825\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 14s 779ms/step - loss: 0.1939 - accuracy: 0.9842\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 14s 769ms/step - loss: 0.1863 - accuracy: 0.9860\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 14s 789ms/step - loss: 0.1791 - accuracy: 0.9877\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 14s 781ms/step - loss: 0.1723 - accuracy: 0.9877\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 14s 769ms/step - loss: 0.1659 - accuracy: 0.9912\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 14s 769ms/step - loss: 0.1599 - accuracy: 0.9912\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 14s 773ms/step - loss: 0.1542 - accuracy: 0.9912\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 14s 784ms/step - loss: 0.1487 - accuracy: 0.9912\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 14s 773ms/step - loss: 0.1436 - accuracy: 0.9930\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 14s 777ms/step - loss: 0.1388 - accuracy: 0.9930\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 14s 786ms/step - loss: 0.1341 - accuracy: 0.9947\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 15s 811ms/step - loss: 0.1298 - accuracy: 0.9947\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 15s 843ms/step - loss: 0.1256 - accuracy: 0.9947\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 15s 830ms/step - loss: 0.1216 - accuracy: 0.9947\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 15s 844ms/step - loss: 0.1178 - accuracy: 0.9947\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 15s 839ms/step - loss: 0.1142 - accuracy: 0.9965\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 15s 850ms/step - loss: 0.1108 - accuracy: 0.9965\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 15s 832ms/step - loss: 0.1075 - accuracy: 0.9965\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 16s 856ms/step - loss: 0.1043 - accuracy: 0.9965\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 15s 845ms/step - loss: 0.1013 - accuracy: 0.9965\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 15s 851ms/step - loss: 0.0984 - accuracy: 0.9965\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 15s 804ms/step - loss: 0.0957 - accuracy: 0.9965\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 14s 798ms/step - loss: 0.0930 - accuracy: 0.9965\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 15s 808ms/step - loss: 0.0905 - accuracy: 0.9982\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 15s 839ms/step - loss: 0.0880 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 15s 804ms/step - loss: 0.0857 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 14s 796ms/step - loss: 0.0834 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 14s 789ms/step - loss: 0.0813 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 14s 786ms/step - loss: 0.0792 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 15s 845ms/step - loss: 0.0772 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 15s 819ms/step - loss: 0.0752 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 14s 789ms/step - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 14s 770ms/step - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 15s 802ms/step - loss: 0.0698 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 15s 822ms/step - loss: 0.0681 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 15s 805ms/step - loss: 0.0665 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 15s 809ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 14s 795ms/step - loss: 0.0634 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 15s 800ms/step - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 15s 799ms/step - loss: 0.0606 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 14s 795ms/step - loss: 0.0592 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 14s 798ms/step - loss: 0.0579 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 14s 766ms/step - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 14s 771ms/step - loss: 0.0553 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 15s 811ms/step - loss: 0.0541 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 16s 898ms/step - loss: 0.0530 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 16s 861ms/step - loss: 0.0518 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 16s 866ms/step - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 16s 857ms/step - loss: 0.0497 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 15s 846ms/step - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 15s 841ms/step - loss: 0.0476 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 15s 839ms/step - loss: 0.0467 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 15s 855ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 16s 870ms/step - loss: 0.0448 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 16s 859ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 15s 847ms/step - loss: 0.0430 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 15s 849ms/step - loss: 0.0422 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 15s 847ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 15s 832ms/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 15s 829ms/step - loss: 0.0398 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 15s 822ms/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 15s 827ms/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 15s 847ms/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 15s 831ms/step - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 14s 776ms/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 14s 800ms/step - loss: 0.0356 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define paths and parameters\n",
    "train_images_dir = 'D:/Data science repo/Weapons_dataset/weapon_detection/train/images'\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "# Function to extract the class label from the filename\n",
    "def extract_label_from_filename(image_file):\n",
    "    base_name = tf.strings.split(image_file, os.sep)[-1]\n",
    "    weapon_name = tf.strings.split(base_name, '_')[0]\n",
    "    return weapon_name\n",
    "\n",
    "# Create a mapping from weapon names to class IDs\n",
    "image_files = [os.path.join(train_images_dir, f) for f in os.listdir(train_images_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "weapon_names = sorted(set(extract_label_from_filename(tf.constant(f)).numpy().decode('utf-8') for f in image_files))\n",
    "class_mapping = {name: i for i, name in enumerate(weapon_names)}\n",
    "\n",
    "# Convert class_mapping to a TensorFlow lookup table\n",
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=tf.constant(weapon_names),\n",
    "        values=tf.constant(list(range(len(weapon_names))), dtype=tf.int32)\n",
    "    ),\n",
    "    default_value=tf.constant(-1)\n",
    ")\n",
    "\n",
    "# Function to load and preprocess the image and extract the label\n",
    "def load_image_and_label(image_file):\n",
    "    img = tf.io.read_file(image_file)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    # Extract the weapon class from the filename\n",
    "    weapon_name = extract_label_from_filename(image_file)\n",
    "    class_id = table.lookup(weapon_name)\n",
    "    \n",
    "    return img, class_id\n",
    "\n",
    "# Create a dataset from image files\n",
    "def generator():\n",
    "    for image_file in image_files:\n",
    "        yield load_image_and_label(image_file)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(img_height, img_width, 3), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "))\n",
    "dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Load MobileNetV2 model with pre-trained weights\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top of MobileNetV2\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(len(class_mapping), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Check dataset shapes\n",
    "for images, labels in dataset.take(1):\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "history = model.fit(dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the model is already compiled and trained\n",
    "def predict_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = preprocess_image(image_path)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img)\n",
    "    \n",
    "    # Get the predicted class ID\n",
    "    predicted_class_id = tf.argmax(predictions[0]).numpy()\n",
    "    \n",
    "    # Map the class ID to the class label\n",
    "    predicted_class_label = [name for name, id in class_mapping.items() if id == predicted_class_id][0]\n",
    "    \n",
    "    return predicted_class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "The predicted label for the sample image is: Bazooka\n"
     ]
    }
   ],
   "source": [
    "sample_image_path = 'bazooka.jpeg'\n",
    "predicted_label = predict_image(sample_image_path)\n",
    "print(f\"The predicted label for the sample image is: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\hvenv2\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('pixelpunk.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
